---
title: "Reporte final de \"Los peces y el mercurio\""
author: "Luis Cano Irigoyen A00827178"
date: "2022-10-26"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Módulo 5 Procesamiento de datos multivariados (Portafolio Implementación)

## Problema

La contaminación por mercurio de peces en el agua dulce comestibles es una amenaza directa contra nuestra salud. Se llevó a cabo un estudio reciente en 53 lagos de Florida con el fin de examinar los factores que influían en el nivel de contaminación por mercurio. 

Variables que se midieron:

- X1 = número de indentificación
- X2 = nombre del lago
- X3 = alcalinidad (mg/l de carbonato de calcio)
- X4 = PH
- X5 = calcio (mg/l)
- X6 = clorofila (mg/l)
- X7 = concentración media de mercurio (parte por millón) en el tejido muscualar del grupo de peces estudiados en cada lago
- X8 = número de peces estudiados en el lago
- X9 = mínimo de la concentración de mercurio en cada grupo de peces
- X10 = máximo de la concentración de mercurio en cada grupo de peces
- X11 = estimación (mediante regresión) de la concentración de mercurio en el pez de 3 años (o promedio de mercurio cuando la edad no está disponible)
- X12 = indicador de la edad de los peces (0: jóvenes; 1: maduros)

## Datos

```{r}
D=read.csv("mercurio.csv")
N=nrow(D)
```

Cambiamos el nombre de las columnas para comprender mejor los análisis

```{r}
colnames(D) <- c("ID","Nombre","Alcalinidad", "PH", "Calcio", "Clorofila", "MediaMercurio",
                    "NumPez", "MinMercurio", "MaxMercurio", "TresMercurio","Edad")
head(D, 5)
```

ID y Nombre no son variables númericas y Edad no es variable continua
No son explicativas, así que las eliminamos

```{r}
D$ID <- NULL
D$Nombre <- NULL
D$Edad <- NULL
```

# 1. Análisis de normalidad de las variables continuas para identificar variables normales.

### A.
Prueba de normalidad de Mardia y prueba de Anderson Darling para identificar las variables que son normales y detectar posible normalidad multivariada de grupos de variables.

Hipótesis:
$H_0:$ Si hay normalidad multivariada

$H_a$: No hay normalidad multivariada

```{r}
library(MVN)
mvn(D, subset = NULL, mvn = "mardia")
```

Contamos con una Mardia Skewness de 434.34 y una Mardia Kurtosis de 5.77
Esta función realiza pruebas de normalidad multivariada de sesgo y curtosis y nos da como resultado que No hay normalidad multivariada. De igual manera, utilizando un nivel de significancia de 0.05, podemos ver como los p-values de sesgo (4.1e-26) y curtosis (7.9e-09) son menores al nivel de significancia, por lo que rechazamos a $H_0$ y determinamos que No hay nomralidad multivariada en las variables.

Con el Test de Anderson-Darling encontramos que las variables que son normales son PH y MaxMercurio

### B.
Prueba de Mardia y Anderson Darling de las variables que sí tuvieron normalidad en los incisos anteriores. 

```{r}
mvn(D[, c("PH", "MaxMercurio") ], mvn = "mardia")
```

A diferencia de la prueba de Mardia con todas las variables, al usar solo las normales (PH y MaxMercurio) obtenemos una curtosis entre -1 y 1, lo cual nos dice que hay normalidad. 
Asímismo, la prueba de normalidad multivariada de sesgo y curtosis realizada nos da como resultado que Si hay normalidad multivariada, y contamos con p-values que son mayores al nivel de significancia.

### C.
Gráfica de contorno de la normal multivariada obtenida en el inciso B.

```{r}
library(mnormt)

# create bivariate normal distribution
x = seq(3, 10, length.out = 100)
y = seq(-0.5, 2.5, length.out = 100)
mu = c(mean(D$PH), mean(D$MaxMercurio))
sigma <- matrix(c(sd(D$PH)^2, 0, 0,sd(D$MaxMercurio)^2),2,2)
z = outer(x, y, function(x, y) dmnorm(cbind(x, y), mu, sigma))

# create contour plot
contour(x, y, z, nlevels = 20, xlab = "PH", ylab = "MaxMercurio")
```

### D.
Detecta datos atípicos o influyentes en la normal multivariada encontrada en el inciso B

```{r}
d = D[, c("PH", "MaxMercurio") ]

p = 2 # usando 2 variables
# Vector de medias
X = colMeans(d)
# Matriz de covarianza
S = cov(d)
# Distancia de Mahalanobis
d2M =  mahalanobis(d,X,S)

# Multinormalidad Test gráfico Q-Q Plot
plot(qchisq(((1:nrow(d)) - 1/2)/nrow(d), df=p), sort( d2M ), main = "Multinormalidad Test gráfico Q-Q Plot", xlab = "Chi^2", ylab = "d^2M")
abline(a=0, b=1,col="red")
```

En la gráfica de distancias de Mahalanobis podemos observar que al inicio los puntos se encuentran cerca de la normalidad multivariada, pero conforme avanza la gráfica en las últimas instancias a la derecha se observa una ligera curva hacia abajo. Los últimos 3 puntos podríamos considerarlos como datos atípicos ya que la distancia se aleja bastante.


# 2. Análisis de componentes principales con la base de datos completa para identificar los factores principales que intervienen en el problema de la contaminación por mercurio de los peces en agua dulce. 

### A.
Justifique por qué es adecuado el uso de componentes principales para analizar la base (haz uso de la matriz de correlaciones)

```{r}
library(ggplot2)
library(ggcorrplot)
ggcorrplot(cor(D), hc.order = TRUE, type = "lower", lab = TRUE, lab_size = 3)
```
Fuera de NumPez, tenemos una tabla llena de correlaciones moderadas, altas y muy altas, con muy pocas correlaciones como Clacio y MinMercurio que podríamos considerar como bajas. Hay mucha dependencia entre las variables, podemos determinar que varios pares como la Aclalinidad y el Calcio explican casi lo mismo.

### B.
Realiza el análisis de componentes principales y justifica el número de componentes principales apropiados para reducir la dimensión de la base

Todo este análisis se relaiza con variables estandarizadas, para que todas contribuyan de la misma manera al análisis

```{r}
library(FactoMineR)
library(factoextra)
pca = PCA(D, scale.unit = TRUE, graph = FALSE)
pca
```

Nuestro análisis genera 9 componentes, de los cuales podemos ver los siguientes resultados:

```{r}
fviz_screeplot(pca, addlabels = TRUE, ylim = c(0, 100))
```

```{r}
pca$eig
```
A partir de los resultados de los Componentes Principales, determinamos que la dimensión de la base puede ser reducida a los primeros 5 componentes, ya que estos representan más del 95% de la variación total.

```{r}
pca5 = PCA(D, scale.unit = TRUE, graph = FALSE, ncp=5)
```

```{r}
pca5$var$contrib
```
En esta tabla podemos ver las contibuciones (en porcentajes) de las 9 variables a los 5 componentes principales.

```{r}
library("corrplot")
corrplot(pca5$var$contrib, is.corr=FALSE)   
```

### C.
Representa en un gráfico los vectores asociados a las variables y las puntuaciones de las observaciones de las dos primeras componentes
```{r}
options(ggrepel.max.overlaps = Inf)
fviz_pca_biplot(pca, repel = TRUE, label = "var", col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```
Vemos como todas las variables menos NumPez contribuyen de magnitud similar a la Dimensión 1, y para la dimensión 2 todas las variables menos NumPez contribuyen con relación positiva, siendo Calcio la que más contribuye a este.

Asímismo podemos ver las contribuciones de las variables a los demás componentes:
```{r}
fviz_contrib(pca, choice = "var", axes = 3)
fviz_contrib(pca, choice = "var", axes = 4)
fviz_contrib(pca, choice = "var", axes = 5)
```


### D.
Interprete los resultados. Explique brevemente a qué conclusiones llega con su análisis y qué significado tienen los componentes seleccionados en el contexto del problema

Podemos observar como todas las variables a excepción de NumPez toman parte en explicar los primeros 2 componentes principales, siendo estos los más importantes explicando el 72.96% de la variación, con variables como Alcalinidad, Calcio y MaxMercurio teniendo un ligero mayor ipacto en estos 2 componentes.  
Sin embargo, los componentes 3, 4 y 5 son mayoritariamente explicados por una sola variable cada uno, siendo NumPez el que contribuye de manera total al componente 3, mayormente Clorofila y poco Calcio para el componente 4, y mayormente PH y poco Clorofila para el componente principal 5.


# 3. Conclusión general

- ¿de qué forma te ayuda este nuevo análisis a contestar la pregunta principal del estudio:  ¿Cuáles son los principales factores que influyen en el nivel de contaminación por mercurio en los peces de los lagos de Florida?   
De este análisis primero encontramos que PH y MaxMercurio son las únicas variables que presentan normalidad multivariada, ya que el conjunto de todas las 9 variables numéricas no presenta una distribución normal multivariada. Esto nos ayuda a determinar que variables podríamos utilizar para buscar generar un mejor modelo que explique los principales factores en el nivel de contaminación por mercurio.  
El análisis de componentes principales de igual manera puede ayudar a encontrar una mejor solución al estudio, ya que crear un modelo con los 5 componentes propuestos que explican el 95.69% de la varianza podría ser de gran utilidad.

- ¿en qué puede facilitar el estudio la normalidad encontrada en un grupo de variables detectadas?   
La normalidad encontrada en un grupo de variables detectadas nos ayuda a determinar cómo se distribuyen las variables y qué variables podríamos utilizar para buscar generar un mejor modelo, ya que si no se cuenta con una normalidad multivariada el modelo no es tan confiable.

- ¿cómo te ayudan los componentes principales a abordar este problema?  
Trabajar con variables que tienen alta correlación entre si llega a ser un problema ya que estas explican cosas similares de la variable dependiente. Cuando realizamos un análisis estadístico deberíamos buscar que las variables independientes tengan correlaciones bajas y expliquen la mayor parte de la varianza total del modelo. Y para esto, en lugar de utilizar las variables en el problema, podemos utilizar un conjunto de componentes principales, los cuales reducen el tamaño de la base, no tienen alta dependencia entre sí, y explican el porcentaje deseado del modelo. En nuestro caso redujimos la base de 9 variables a 5 componentes que explicaran más del 95% de la varianza.


